# ICCV2023-Accepted-Papers

# Day 3: Wednesday 4th 09:30-10:30 - Orals
## Session: 3D from multi-view and sensors 

### Multi-Modal Neural Radiance Field for Monocular Dense SLAM with a Light-Weight ToF Sensor
- [Arxiv](https://arxiv.org/abs/2308.14383) / [Code](https://github.com/zju3dv/tof_slam) / [Project page](https://zju3dv.github.io/tof_slam/)
- Team: State Key Lab of CAD & CG, Zhejiang University ([link](http://www.cad.zju.edu.cn/english.html))

### ScanNet++: A High-Fidelity Dataset of 3D Indoor Scenes
- [Arxiv](https://arxiv.org/abs/2308.11417) / [Code](https://cy94.github.io/scannetpp/#code-toolkit) / [Project page](https://cy94.github.io/scannetpp/)
- Team: 3D AI Lab, Technical University of Munich ([link](https://www.3dunderstanding.org/index.html))

### Translating Images to Road Network: A Non-Autoregressive Sequence-to-Sequence Approach
- [Arxiv(Comming)]() / [Code(Comming)]() / [Project page(Comming)]()
- Team: Zhang-vsion Group, Fudan University ([link](https://fudan-zvg.github.io))

### Doppelgangers: Learning to Disambiguate Images of Similar Structures
- [Arxiv](https://arxiv.org/pdf/2309.02420.pdf) / [Code](https://github.com/RuojinCai/Doppelgangers) / [Project page](https://doppelgangers-3d.github.io)
- Team: (Prof. Bharath Hariharan, Prof. Noah Snavely [link](http://home.bharathh.info/) / [link2](https://www.cs.cornell.edu/~snavely/))

### EgoLoc: Revisiting 3D Object Localization from Egocentric Videos with Visual Queries
- [Arxiv](https://arxiv.org/abs/2212.06969) / [Code](https://github.com/Wayne-Mai/EgoLoc) / [Project page(N/A)]()
- Team: Image and Video Understanding Laboratory (IVUL), King Abdullah University of Science and Technology (KAUST)([link](https://cemse.kaust.edu.sa/ivul))

### ClothPose: A Real-world Benchmark for Visual Analysis of Garment Pose via An Indirect Recording Solution
- [Arxiv(Comming)]() / [Code(Comming)]() / [Project page(Comming)]()
- Team: Shanghai Jiao Tong University([link(Comming)]())

### EMR-MSF: Self-Supervised Recurrent Monocular Scene Flow Exploiting Ego-Motion Rigidity
- [Arxiv](https://arxiv.org/abs/2309.01296) / [Code(Comming)]() / [Project page(Comming)]()
- Team: Okutomi & Tanaka Lab, Tokyo Institute of Technology ([link](http://www.ok.sc.e.titech.ac.jp/mem/member.shtml))

### ENVIDR: Implicit Differentiable Renderer with Neural Environment Lighting
- [Arxiv](https://arxiv.org/abs/2303.13022) / [Code](https://github.com/nexuslrf/ENVIDR) / [Project page](https://nexuslrf.github.io/ENVIDR/)
- Team: EMBARC RESEARCH GROUP, University of Toronto ([link](https://www.cs.toronto.edu/~nandita/index.html))



